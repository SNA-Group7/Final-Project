---
title: "SNAP"
author: "Group 7"
date: today
execute:
  echo: false
format: 
  pdf:
      output-file: "SNAP"
      output-ext: "pdf"
      toc: true
      toc-depth: 4
      shift-heading-level-by: 2
      fig-pos: "H"
      fig-cap-location: top
      geometry:
        - top=1in
        - right=.8in
        - bottom=1in
        - left=.8in
      link-citations: true
      linkcolor: blue
      include-in-header: 
        text: |
          \usepackage{fancyhdr}
          \usepackage{titling}
          \pagestyle{fancy}
          \fancyhf{}
          \renewcommand\maketitle{
            \fancyhead[C]{
              \thetitle
              \ifx \theauthor\empty  \else \ – \theauthor \fi
              \ifx \thedate\empty  \else \ – \thedate \ \fi
            }
          }
          \fancyfoot[C]{\thepage}
---

```{r}
#| label: libraries
#| echo: false
#| output: false
#| message: false

rm(list=ls())

# Start with a clear environment
rm(list=ls())

# Load necessary packages
if (!"devtools" %in% installed.packages()) install.packages("devtools") ## for the install_version function
library(devtools)
if (!"RSiena" %in% installed.packages()) install.packages("RSiena") ## install latest version 
library(RSiena)
packageVersion("RSiena")
library(statnet)
library(readr)
library(dplyr)
library(tidyr)
library(sna)
library(igraph)



# ---------------------------------------------------------------------------------------------
# Set the working directory:
# Session > Set Working Directory > To Source File Location
# ---------------------------------------------------------------------------------------------
list.files() # List the files in the current working directory to see if you're in the right directory

# For more information about the packages we're using in this lab...
# ?RSiena
# ?sienaNet
```

# Dataset Preprocessing

## Prune the Dataset

```{r}
## Process Raw Dataset ##
# Read and Shrink Dataset
selected_columns <- c("_id", 
                      "date_updated",
                      "payment.actor.username", 
                      "payment.target.user.username",
                      "note",
                      "app.description",
                      "payment.action")

venmo_df <- read_csv("venmo.csv", col_select = all_of(selected_columns), n_max=7000000)
venmo_df <- venmo_df %>%
  rename(
    date = date_updated,
    sender = payment.actor.username,
    recipient = payment.target.user.username,
    note = note,
    phone_type = app.description,
    payment_type = payment.action
  )

# Remove Null Rows # Move this above
venmo_df <- venmo_df %>%
  filter(complete.cases(select(., all_of(c("date", "sender", "recipient", "note", "phone_type", "payment_type")))))

## Snowballing (Want to include popular users, their friends, and the friends of their friends)
# Unique Interactions (All components should be at least size 10)
unique_interactions <- venmo_df %>%
  rowwise() %>%
  mutate(interaction = paste(sort(c(sender, recipient)), collapse = "_")) %>%
  distinct(interaction, .keep_all = TRUE)

# Get Popular Users (10+ Transactions)
popular_threshold <- 10
popular_users <- unique_interactions %>%
  pivot_longer(cols = c(sender, recipient), names_to = "type", values_to = "username") %>%
  count(username, name = "count") %>%
  arrange(desc(count)) %>%
  filter(count > popular_threshold)
# Get Friends of Popular Users (Transaction with Popular User)
popular_usernames <- popular_users$username
friends_of_popular_users <- venmo_df %>%
  filter(sender %in% popular_usernames | recipient %in% popular_usernames)

users_of_interest <- friends_of_popular_users %>%
  select(sender, recipient) %>%
  pivot_longer(cols = c(sender, recipient), names_to = "type", values_to = "username") 


# Get Shrunk Dataset
usernames_of_interest = users_of_interest$username
pruned_venmo_df <- venmo_df %>%
  filter(sender %in% usernames_of_interest | recipient %in% usernames_of_interest)

# Save it
write.csv(pruned_venmo_df, file = "pruned_venmo.csv", row.names = FALSE)

```

```{r}
## Prep Datasets ##
# Load Dataset
pruned_venmo_df <- read_csv("pruned_venmo.csv")
head(pruned_venmo_df)

# Split By Date #
#NOTE: Possible that should do popular_user stuff per Date Range Network
#July 2018 - September 2018
jul_sep_transaction_df <- pruned_venmo_df %>% filter(pruned_venmo_df$date >= as.POSIXct("2018-07-01 00:00:00")
                                               & pruned_venmo_df$date < as.POSIXct("2018-10-01 00:00:00"))
jul_sep_transaction_df <- jul_sep_transaction_df[, c("sender", "recipient", "payment_type")]
#October 2018
oct_transaction_df <- pruned_venmo_df %>% filter(pruned_venmo_df$date >= as.POSIXct("2018-10-01 00:00:00")
                                               & pruned_venmo_df$date < as.POSIXct("2018-11-01 00:00:00"))
oct_transaction_df <- oct_transaction_df[, c("sender", "recipient", "payment_type")]

#Jan 2019 - Feb 2019
jan_feb_transaction_df <- pruned_venmo_df %>% filter(pruned_venmo_df$date >= as.POSIXct("2019-01-01 00:00:00")
                                               & pruned_venmo_df$date < as.POSIXct("2019-03-01 00:00:00"))
jan_feb_transaction_df <- jan_feb_transaction_df[, c("sender", "recipient", "payment_type")]


# Transactions
all_transaction_df <- pruned_venmo_df[, c("sender", "recipient", "payment_type")]

# Phone Type
phone_df <- pruned_venmo_df[, c("sender", "phone_type")]
phone_df <- phone_df[!duplicated(phone_df$sender), ]
non_senders <- setdiff(pruned_venmo_df$recipient, unique(pruned_venmo_df$sender))
non_senders_df <- data.frame(
  sender = non_senders,
  phone_type = "unknown",
  stringsAsFactors = FALSE
)
phone_df <- rbind(phone_df, non_senders_df)
phone_df$phone_type[!(phone_df$phone_type %in% c("Venmo for Android", "Venmo for iPhone", "unknown"))] <- "other" #Known venmo application but not Apple or Android
```

## Construct the Networks

```{r}
## Build the Networks ##
#detach("package:igraph", unload = TRUE)
#library(network)
#Full Network#
all_transactions_net <- graph_from_data_frame(d = all_transaction_df, 
                                              directed = TRUE, 
                                              vertices = NULL)
# Label Directed Links
E(all_transactions_net)$type <- all_transaction_df$payment_type
# Add Phone Types
phone_types <- setNames(phone_df$phone_type, phone_df$sender)
V(all_transactions_net)$phone_type <- phone_types[V(all_transactions_net)$name]

edge_attr(all_transactions_net)
vertex_attr(all_transactions_net)

### UNUSED ###
# #July-September Network#
# jul_sep_transactions_net <- graph_from_data_frame(d = jul_sep_transaction_df, 
#                                               directed = TRUE, 
#                                               vertices = NULL)
# # Label Directed Links
# E(jul_sep_transactions_net)$type <- jul_sep_transaction_df$payment_type
# # Add Phone Types
# V(jul_sep_transactions_net)$phone_type <- phone_types[V(jul_sep_transactions_net)$name]
# 
# #October Network#
# oct_transactions_net <- graph_from_data_frame(d = oct_transaction_df, 
#                                               directed = TRUE, 
#                                               vertices = NULL)
# # Label Directed Links
# E(oct_transactions_net)$type <- oct_transaction_df$payment_type
# # Add Phone Types
# V(oct_transactions_net)$phone_type <- phone_types[V(oct_transactions_net)$name]
# 
# #January-February Network#
# jan_feb_transactions_net <- graph_from_data_frame(d = jan_feb_transaction_df, 
#                                               directed = TRUE, 
#                                               vertices = NULL)
# # Label Directed Links
# E(jan_feb_transactions_net)$type <- jan_feb_transaction_df$payment_type
# # Add Phone Types
# V(jan_feb_transactions_net)$phone_type <- phone_types[V(jan_feb_transactions_net)$name]
```

# Descriptive Analysis

Finding: During preprocessing, popular users (at least 10 transactions) are found based on their transactions throughout all time. However, based on the below, popular users in the July2018-Feb2019 range are not popular within the three smaller ranges. Thus, may need to get popular users per range (or not compare across ranges at all). Likely need to make different "pruned" datasets for each range if want to do this.

all_transactions:

This network was created by going through the original dataset and pruning it so it'd be easier to work with. First, all users with at least 10 unique transactions are found. Then, the neighbors of these "popular" users and the neighbors of the neighbors are found. Then, a new dataset called pruned_venmo is made by only keeping track of transactions with users from these 3 groups. Doing this causes all 2010 components in the network to have a size of at least 10 (which is demonstrated below). Most components have under 300 nodes, so to make analysis more interesting, we choose to look at the largest one of 248,884 nodes and 316, 400 edges. It also has a density of 5.107922e-06, meaning the network is very sparse, which would be expected in large social networks. Due to its size, it's difficult to make conclusions from its visualization, but it seems that it grows increasingly clustered towards the middle.

In the largest component, 260,922 of transactions are Payments, while only 55,478 are Charges. In addition, 163,179 users use iPhone, 13,038 use Android, and 455 use some other platform. Unfortunately, due to the nature of the dataset, it's only possible to know the phone type of Senders (sent a transaction), so 72,212 have an unknown application type.

Specific Date Range Networks:

The "popular" users across all_transactions are not popular within the date ranges. This means that within the ranges of July-September, October, and January-February, no user has 10 unique interactions. To decrease the sparsity of the components in these networks, "popular" user preprocessing must be done on these ranges individually.

```{r}
library(igraph)
library(intergraph)
## Network Descriptions ##
# Full Network #
# Components 
all_comp <- components(all_transactions_net); all_comp$no
all_comp$csize
giantGraph_all <- all_transactions_net %>% 
  induced.subgraph(., which(all_comp$membership == which.max(all_comp$csize)))
print(vcount(giantGraph_all)) # Nodes
print(ecount(giantGraph_all)) # Edges
graph.density(giantGraph_all)
table(E(giantGraph_all)$type)
table(V(giantGraph_all)$phone_type)

plot(giantGraph_all, vertex.size = 1, vertex.label = NA)

###UNUSED###
# # July-September Network #
# # Components
# july_sep_comp <- components(july_sep_transactions_net); july_sep_comp$no
# july_sep_comp$csize
# giantGraph_july_sep <- july_sep_transactions_net %>%
#   induced.subgraph(., which(july_sep_comp$membership == which.max(july_sep_comp$csize)))
# 
# # October Network #
# # Components
# oct_comp <- components(oct_transactions_net); oct_comp$no
# oct_comp$csize
# giantGraph_oct <- oct_transactions_net %>%
#   induced.subgraph(., which(oct_comp$membership == which.max(oct_comp$csize)))
# 
# # January-February Network #
# # Components
# jan_feb_comp <- components(jan_feb_transactions_net); jan_feb_comp$no
# jan_feb_comp$csize
# giantGraph_jan_feb <- jan_feb_transactions_net %>%
#   induced.subgraph(., which(jan_feb_comp$membership == which.max(jan_feb_comp$csize)))
```

```{r}
```

# Community Detection

cluster_all: Used the infomap community detection algorithm as it works well for very large directed graphs. Using the algorithm, 24,744 communties were found. Based on the first 1,000 communities, their sizes were mostly in the 50-200 range. Their modularity score is 0.85, meaning the communities are very well-defined (likely due to the sparsity of the network). Once again, it's difficult to discern much from the visualization due to its size.

```{r}
## Clustering All ##
cluster_all <- giantGraph_all %>% cluster_infomap()
community_membership_all <- membership(cluster_all) 

length(cluster_all) # Number of clusters
sizes(cluster_all)  # Size of Clusters
modularity(cluster_all) # How well-defined the clusters are

cluster_all %>% plot(
  .,
  giantGraph_all,
  # layout = layout_with_gem(.),
  layout = layout_with_fr(giantGraph_all),
  edge.arrow.size = .3,
  vertex.size = 4,
  vertex.label = NA,
  vertex.color = adjustcolor(membership(.), alpha.f = .3),
  vertex.label.cex = .5,
  vertex.label.color = 'black',
  mark.groups = by(seq_along(membership(.)), membership(.), invisible),
  mark.shape = 1 / 4,
  mark.col = rainbow(length(.), alpha = .1),
  mark.border = NA
)
```

## Influencers

```{r}
# Find Influencers #
# All
indegrees <- degree(giantGraph_all, mode = "in")
influencer_nodes <- order(indegrees, decreasing = TRUE)[1:1000]
global_influencers = data.frame(username = V(giantGraph_all)$name[influencer_nodes],
                                indegree = indegrees[influencer_nodes])
# Per Community
community_influencers <- data.frame(
  username = character(),
  indegree = integer(),
  community = integer())
# Loop over each community
for (community in unique(community_membership)) {
  community_nodes <- V(giantGraph_all)[community_membership == community]
    
  # Get Community Influencer
  indegrees <- degree(giantGraph_all, mode = "in", v = community_nodes)
  influencer_indegree_value <- max(indegrees)
  influencer_node <- which(indegrees == influencer_indegree_value)
  influencer_username <- V(giantGraph_all)$name[community_nodes][influencer_node]
  # Add to Dataframe
  influencer <- data.frame(
    username = influencer_username,
    indegree = influencer_indegree_value,
    community = community)
  community_influencers <- rbind(community_influencers, influencer)  
}
```

## Comparing Global vs. Local Influencers

Findings:

Global: 424 of the Top 1000 Indegree Users (Receive the most transactions) never send a transaction. 475 use iPhone.

Local: 11592/24744 communities have influencers who never send a transaction. 21251 use iPhone

Both: Global Influencers are not Local Influencers in multiple communities. Generally, they just appear in 1 community. No Local Influencer is a Local Influencer in multiple communities.

```{r}
# Phone Type
global_influencers <- merge(global_influencers, phone_df, by.x = "username", by.y = "sender", all.x = TRUE)
global_influencers <- global_influencers[order(-global_influencers$indegree), ]
table(head(global_influencers, 1000)$phone_type)

community_influencers <- merge(community_influencers, phone_df, by.x = "username", by.y = "sender", all.x = TRUE)
table(community_influencers$phone_type)


# Compare Directly
top_50_global_influencers <- head(global_influencers, 50)
community_counts <- table(community_influencers$username)
global_influencer_counts <- community_counts[top_50_global_influencers$username]
global_influencer_counts[is.na(global_influencer_counts)] <- 0
global_influencer_counts
community_counts
```

# ERGM
